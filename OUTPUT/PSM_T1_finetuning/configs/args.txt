==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning/finetuned_checkpoint-10.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning/finetuned_checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.0.1+cu117
==> cudnn version: 8500
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_pre_training_24/checkpoint-10.pt', '--finetune']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: True
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_pre_training_24/checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 2001
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/finetuned_checkpoint-10.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--pretrained_path', './Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: ./Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
==> torch version: 2.4.1+cu121
==> cudnn version: 90100
==> Cmd:
['main.py', '--name', 'PSM_T1_finetuning', '--config_file', 'Config/PSM_T1_finetuning.yaml', '--finetune_path', './Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt', '--size_every', '100']
==> args:
  config_file: Config/PSM_T1_finetuning.yaml
  cudnn_deterministic: False
  fault_data: None
  finetune: False
  finetune_path: ./Checkpoints_PSM_T1_finetuning_24/checkpoint-finetune-23000.pt
  gpu: None
  milestone: 3
  missing_ratio: 0.0
  mode: infill
  name: PSM_T1_finetuning
  opts: []
  output: OUTPUT
  pred_len: 0
  pretrained_path: None
  sample: 0
  save_dir: OUTPUT/PSM_T1_finetuning
  seed: 12345
  size_every: 100
  tensorboard: False
  train: False
